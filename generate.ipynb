{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from langchain_community.document_loaders import  TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "# from langchain_core.document_loaders.base import Document\n",
    "from pathlib import Path\n",
    "import random\n",
    "from helpers.df_helpers import documents2Dataframe\n",
    "from helpers.df_helpers import df2Graph\n",
    "from helpers.df_helpers import graph2Df\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "import csv"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"cureus\"\n",
    "inputdirectory = Path(f\"./data_input/{data_dir}\")\n",
    "out_dir = data_dir\n",
    "outputdirectory = Path(f\"./data_output/{out_dir}\")\n",
    "txt_files = list(inputdirectory.glob(\"*.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colors2Community(communities) -> pd.DataFrame:\n",
    "    ## Define a color palette\n",
    "    p = sns.color_palette(palette, len(communities)).as_hex()\n",
    "    random.shuffle(p)\n",
    "    rows = []\n",
    "    group = 0\n",
    "    for community in communities:\n",
    "        color = p.pop()\n",
    "        group += 1\n",
    "        for node in community:\n",
    "            rows += [{\"node\": node, \"color\": color, \"group\": group}]\n",
    "    df_colors = pd.DataFrame(rows)\n",
    "    return df_colors\n",
    "def contextual_proximity(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    ## Melt the dataframe into a list of nodes\n",
    "    dfg_long = pd.melt(\n",
    "        df, id_vars=[\"chunk_id\"], value_vars=[\"node_1\", \"node_2\"], value_name=\"node\"\n",
    "    )\n",
    "    dfg_long.drop(columns=[\"variable\"], inplace=True)\n",
    "    # Self join with chunk id as the key will create a link between terms occuring in the same text chunk.\n",
    "    dfg_wide = pd.merge(dfg_long, dfg_long, on=\"chunk_id\", suffixes=(\"_1\", \"_2\"))\n",
    "    # drop self loops\n",
    "    self_loops_drop = dfg_wide[dfg_wide[\"node_1\"] == dfg_wide[\"node_2\"]].index\n",
    "    dfg2 = dfg_wide.drop(index=self_loops_drop).reset_index(drop=True)\n",
    "    ## Group and count edges.\n",
    "    dfg2 = (\n",
    "        dfg2.groupby([\"node_1\", \"node_2\"])\n",
    "        .agg({\"chunk_id\": [\",\".join, \"count\"]})\n",
    "        .reset_index()\n",
    "    )\n",
    "    dfg2.columns = [\"node_1\", \"node_2\", \"chunk_id\", \"count\"]\n",
    "    dfg2.replace(\"\", np.nan, inplace=True)\n",
    "    dfg2.dropna(subset=[\"node_1\", \"node_2\"], inplace=True)\n",
    "    # Drop edges with 1 count\n",
    "    dfg2 = dfg2[dfg2[\"count\"] != 1]\n",
    "    dfg2[\"edge\"] = \"contextual proximity\"\n",
    "    return dfg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks for 6.txt =  31\n",
      "Shape of DataFrame for 6.txt =  (31, 3)\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\知识图谱\\helpers\\New_langchain_tongyi.py:59: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm=llm, prompt=A_prompt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ERROR ### Here is the buggy response:  Here is the structured JSON output based on the extracted terms and their relationships from the context:\n",
      "\n",
      "\n",
      "[\n",
      "  {\n",
      "    \"node_1\": \"Spiking Neural Networks (SNNs)\",\n",
      "    \"node_2\": \"Neural spikes\",\n",
      "    \"edge\": \"Spiking neural networks exploit neural spikes for computation.\"\n",
      "  },\n",
      "  {\n",
      "    \"node_1\": \"Spiking Neural Networks (SNNs)\",\n",
      "    \"node_2\": \"Low-power intelligent applications\",\n",
      "    \"edge\": \"SNNs provide solutions for low-power intelligent applications.\"\n",
      "  },\n",
      "  {\n",
      "    \"node_1\": \"Spiking Neural Networks (SNNs)\",\n",
      "    \"node_2\": \"Neuromorphic hardware\",\n",
      "    \"edge\": \"SNNs are implemented on neuromorphic hardware for efficiency.\"\n",
      "  },\n",
      "  {\n",
      "    \"node_1\": \"Spiking Neural Networks (SNNs)\",\n",
      "    \"node_2\": \"Computational efficiency\",\n",
      "    \"edge\": \"SNNs have high computational efficiency due to spiking communication.\"\n",
      "  },\n",
      "  {\n",
      "    \"node_1\": \"Spiking Neural Networks (SNNs)\",\n",
      "    \"node_2\": \"Adversarial attacks\",\n",
      "    \"edge\": \"SNNs lack resistance to adversarial attacks.\"\n",
      "  },\n",
      "  {\n",
      "    \"node_1\": \"Spiking Neural Networks (SNNs)\",\n",
      "    \"node_2\": \"Noise perturbations\",\n",
      "    \"edge\": \"SNNs are vulnerable to noise perturbations.\"\n",
      "  },\n",
      "  {\n",
      "    \"node_1\": \"Neuronal responses\",\n",
      "    \"node_2\": \"Stochasticity\",\n",
      "    \"edge\": \"Neuronal responses in the brain possess stochasticity.\"\n",
      "  },\n",
      "  {\n",
      "    \"node_1\": \"Stochasticity\",\n",
      "    \"node_2\": \"Ion channels\",\n",
      "    \"edge\": \"Stochasticity in neuronal responses is induced by ion channels.\"\n",
      "  },\n",
      "  {\n",
      "    \"node_1\": \"Stochasticity\",\n",
      "    \"node_2\": \"Synapses\",\n",
      "    \"edge\": \"Stochasticity in neuronal responses is induced by synapses.\"\n",
      "  },\n",
      "  {\n",
      "    \"node_1\": \"Stochasticity\",\n",
      "    \"node_2\": \"Computing tasks\",\n",
      "    \"edge\": \"The role of stochasticity in computing tasks is poorly understood.\"\n",
      "  },\n",
      "  {\n",
      "    \"node_1\": \"Stochastic gating spiking neural model\",\n",
      "    \"node_2\": \"Spiking Neural Networks (SNNs)\",\n",
      "    \"edge\": \"The stochastic gating model introduces stochasticity to SNNs.\"\n",
      "  },\n",
      "  {\n",
      "    \"node_1\": \"Stochastic gating spiking neural model\",\n",
      "    \"node_2\": \"Layer-by-layer spike communication\",\n",
      "    \"edge\": \"The model facilitates layer-by-layer spike communication.\"\n",
      "  },\n",
      "  {\n",
      "    \"node_1\": \"Stochastic gating spiking neural model\",\n",
      "    \"node_2\": \"Regularizer\",\n",
      "    \"edge\": \"The gating model acts as a regularizer in SNNs.\"\n",
      "  },\n",
      "  {\n",
      "    \"node_1\": \"Regularizer\",\n",
      "    \"node_2\": \"Error amplification\",\n",
      "    \"edge\": \"The regularizer prevents error amplification under attacks.\"\n",
      "  },\n",
      "  {\n",
      "    \"node_1\": \"Stochastic gating spiking neural model\",\n",
      "    \"node_2\": \"Poisson coding\",\n",
      "    \"edge\": \"The model explains the robustness of Poisson coding.\"\n",
      "  },\n",
      "  {\n",
      "    \"node_1\": \"Stochastic gating spiking neural model\",\n",
      "    \"node_2\": \"SNN robustness\",\n",
      "    \"edge\": \"The model improves SNN robustness.\"\n",
      "  },\n",
      "  {\n",
      "    \"node_1\": \"Stochastic gating spiking neural model\",\n",
      "    \"node_2\": \"Energy consumption\",\n",
      "    \"edge\": \"The model reduces SNN energy consumption.\"\n",
      "  },\n",
      "  {\n",
      "    \"node_1\": \"Stochastic gating spiking neural model\",\n",
      "    \"node_2\": \"Code repository\",\n",
      "    \"edge\": \"The model's code is available on GitHub.\"\n",
      "  },\n",
      "  {\n",
      "    \"node_1\": \"Spiking Neural Networks (SNNs)\",\n",
      "    \"node_2\": \"Low-energy neural network systems\",\n",
      "    \"edge\": \"SNNs are representatives of low-energy neural network systems.\"\n",
      "  },\n",
      "  {\n",
      "    \"node_1\": \"Spiking Neural Networks (SNNs)\",\n",
      "    \"node_2\": \"Artificial Neural Networks (ANN)\",\n",
      "    \"edge\": \"SNNs differ from ANN in using spikes instead of floating-point.\"\n",
      "  },\n",
      "  {\n",
      "    \"node_1\": \"Spiking Neural Networks (SNNs)\",\n",
      "    \"node_2\": \"Floating-point representations\",\n",
      "    \"edge\": \"SNNs use spikes instead of floating-point representations.\"\n",
      "  },\n",
      "  {\n",
      "    \"node_1\": \"Spiking Neural Networks (SNNs)\",\n",
      "    \"node_2\": \"Deep learning\",\n",
      "    \"edge\": \"SNNs are studied from a deep learning perspective.\"\n",
      "  }\n",
      "] \n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'code': 'RequestTimeOut', 'param': None, 'message': 'Request timed out, please try again later.', 'type': 'RequestTimeOut'}, 'id': 'chatcmpl-8d5bbf13-fcb2-95b1-aed4-753888606061', 'request_id': '8d5bbf13-fcb2-95b1-aed4-753888606061'}",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mBadRequestError\u001B[39m                           Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 33\u001B[39m\n\u001B[32m     27\u001B[39m df = documents2Dataframe(pages)\n\u001B[32m     28\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mShape of DataFrame for \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtxt_file.name\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m = \u001B[39m\u001B[33m\"\u001B[39m, df.shape)\n\u001B[32m---> \u001B[39m\u001B[32m33\u001B[39m concepts_list = \u001B[43mdf2Graph\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mgpt-4\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     34\u001B[39m dfg1 = graph2Df(concepts_list)\n\u001B[32m     35\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os.path.exists(outputdirectory):\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\python\\知识图谱\\helpers\\df_helpers.py:54\u001B[39m, in \u001B[36mdf2Graph\u001B[39m\u001B[34m(dataframe, model)\u001B[39m\n\u001B[32m     52\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33m2\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     53\u001B[39m \u001B[38;5;66;03m# dataframe.reset_index(inplace=True)\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m54\u001B[39m results = \u001B[43mdataframe\u001B[49m\u001B[43m.\u001B[49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     55\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrow\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mTYgraphPrompt\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrow\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mchunk_id\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mrow\u001B[49m\u001B[43m.\u001B[49m\u001B[43mchunk_id\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m1\u001B[39;49m\n\u001B[32m     56\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     57\u001B[39m \u001B[38;5;66;03m# invalid json results in NaN\u001B[39;00m\n\u001B[32m     58\u001B[39m results = results.dropna()\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\python\\知识图谱\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:10374\u001B[39m, in \u001B[36mDataFrame.apply\u001B[39m\u001B[34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001B[39m\n\u001B[32m  10360\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpandas\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mcore\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mapply\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m frame_apply\n\u001B[32m  10362\u001B[39m op = frame_apply(\n\u001B[32m  10363\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m  10364\u001B[39m     func=func,\n\u001B[32m   (...)\u001B[39m\u001B[32m  10372\u001B[39m     kwargs=kwargs,\n\u001B[32m  10373\u001B[39m )\n\u001B[32m> \u001B[39m\u001B[32m10374\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mop\u001B[49m\u001B[43m.\u001B[49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m.__finalize__(\u001B[38;5;28mself\u001B[39m, method=\u001B[33m\"\u001B[39m\u001B[33mapply\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\python\\知识图谱\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:916\u001B[39m, in \u001B[36mFrameApply.apply\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    913\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.raw:\n\u001B[32m    914\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.apply_raw(engine=\u001B[38;5;28mself\u001B[39m.engine, engine_kwargs=\u001B[38;5;28mself\u001B[39m.engine_kwargs)\n\u001B[32m--> \u001B[39m\u001B[32m916\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\python\\知识图谱\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:1063\u001B[39m, in \u001B[36mFrameApply.apply_standard\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1061\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mapply_standard\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m   1062\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.engine == \u001B[33m\"\u001B[39m\u001B[33mpython\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m-> \u001B[39m\u001B[32m1063\u001B[39m         results, res_index = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mapply_series_generator\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1064\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1065\u001B[39m         results, res_index = \u001B[38;5;28mself\u001B[39m.apply_series_numba()\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\python\\知识图谱\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:1081\u001B[39m, in \u001B[36mFrameApply.apply_series_generator\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1078\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m option_context(\u001B[33m\"\u001B[39m\u001B[33mmode.chained_assignment\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[32m   1079\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m i, v \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(series_gen):\n\u001B[32m   1080\u001B[39m         \u001B[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1081\u001B[39m         results[i] = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1082\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(results[i], ABCSeries):\n\u001B[32m   1083\u001B[39m             \u001B[38;5;66;03m# If we have a view on v, we need to make a copy because\u001B[39;00m\n\u001B[32m   1084\u001B[39m             \u001B[38;5;66;03m#  series_generator will swap out the underlying data\u001B[39;00m\n\u001B[32m   1085\u001B[39m             results[i] = results[i].copy(deep=\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\python\\知识图谱\\helpers\\df_helpers.py:55\u001B[39m, in \u001B[36mdf2Graph.<locals>.<lambda>\u001B[39m\u001B[34m(row)\u001B[39m\n\u001B[32m     52\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33m2\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     53\u001B[39m \u001B[38;5;66;03m# dataframe.reset_index(inplace=True)\u001B[39;00m\n\u001B[32m     54\u001B[39m results = dataframe.apply(\n\u001B[32m---> \u001B[39m\u001B[32m55\u001B[39m     \u001B[38;5;28;01mlambda\u001B[39;00m row: \u001B[43mTYgraphPrompt\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrow\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mchunk_id\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mrow\u001B[49m\u001B[43m.\u001B[49m\u001B[43mchunk_id\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m, axis=\u001B[32m1\u001B[39m\n\u001B[32m     56\u001B[39m )\n\u001B[32m     57\u001B[39m \u001B[38;5;66;03m# invalid json results in NaN\u001B[39;00m\n\u001B[32m     58\u001B[39m results = results.dropna()\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\python\\知识图谱\\helpers\\New_langchain_tongyi.py:62\u001B[39m, in \u001B[36mTYgraphPrompt\u001B[39m\u001B[34m(prompt, metadata, model)\u001B[39m\n\u001B[32m     59\u001B[39m chain = LLMChain(llm=llm, prompt=A_prompt)\n\u001B[32m     61\u001B[39m \u001B[38;5;66;03m# response = chain.invoke(prompt).get(\"text\", \"\")\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m62\u001B[39m response = \u001B[43mchain\u001B[49m\u001B[43m.\u001B[49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m)\u001B[49m.get(\u001B[33m\"\u001B[39m\u001B[33mtext\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33m\"\u001B[39m).replace(\u001B[33m'\u001B[39m\u001B[33m```json\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33m'\u001B[39m).replace(\u001B[33m'\u001B[39m\u001B[33m```\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33m'\u001B[39m).strip()\n\u001B[32m     64\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m     65\u001B[39m     result = json.loads(response)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\python\\知识图谱\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py:170\u001B[39m, in \u001B[36mChain.invoke\u001B[39m\u001B[34m(self, input, config, **kwargs)\u001B[39m\n\u001B[32m    168\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    169\u001B[39m     run_manager.on_chain_error(e)\n\u001B[32m--> \u001B[39m\u001B[32m170\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[32m    171\u001B[39m run_manager.on_chain_end(outputs)\n\u001B[32m    173\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m include_run_info:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\python\\知识图谱\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py:160\u001B[39m, in \u001B[36mChain.invoke\u001B[39m\u001B[34m(self, input, config, **kwargs)\u001B[39m\n\u001B[32m    157\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    158\u001B[39m     \u001B[38;5;28mself\u001B[39m._validate_inputs(inputs)\n\u001B[32m    159\u001B[39m     outputs = (\n\u001B[32m--> \u001B[39m\u001B[32m160\u001B[39m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    161\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m new_arg_supported\n\u001B[32m    162\u001B[39m         \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m._call(inputs)\n\u001B[32m    163\u001B[39m     )\n\u001B[32m    165\u001B[39m     final_outputs: Dict[\u001B[38;5;28mstr\u001B[39m, Any] = \u001B[38;5;28mself\u001B[39m.prep_outputs(\n\u001B[32m    166\u001B[39m         inputs, outputs, return_only_outputs\n\u001B[32m    167\u001B[39m     )\n\u001B[32m    168\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\python\\知识图谱\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py:126\u001B[39m, in \u001B[36mLLMChain._call\u001B[39m\u001B[34m(self, inputs, run_manager)\u001B[39m\n\u001B[32m    121\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_call\u001B[39m(\n\u001B[32m    122\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    123\u001B[39m     inputs: Dict[\u001B[38;5;28mstr\u001B[39m, Any],\n\u001B[32m    124\u001B[39m     run_manager: Optional[CallbackManagerForChainRun] = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m    125\u001B[39m ) -> Dict[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mstr\u001B[39m]:\n\u001B[32m--> \u001B[39m\u001B[32m126\u001B[39m     response = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    127\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.create_outputs(response)[\u001B[32m0\u001B[39m]\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\python\\知识图谱\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py:138\u001B[39m, in \u001B[36mLLMChain.generate\u001B[39m\u001B[34m(self, input_list, run_manager)\u001B[39m\n\u001B[32m    136\u001B[39m callbacks = run_manager.get_child() \u001B[38;5;28;01mif\u001B[39;00m run_manager \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    137\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m.llm, BaseLanguageModel):\n\u001B[32m--> \u001B[39m\u001B[32m138\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mllm\u001B[49m\u001B[43m.\u001B[49m\u001B[43mgenerate_prompt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    139\u001B[39m \u001B[43m        \u001B[49m\u001B[43mprompts\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    140\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    141\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    142\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mllm_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    143\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    144\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    145\u001B[39m     results = \u001B[38;5;28mself\u001B[39m.llm.bind(stop=stop, **\u001B[38;5;28mself\u001B[39m.llm_kwargs).batch(\n\u001B[32m    146\u001B[39m         cast(List, prompts), {\u001B[33m\"\u001B[39m\u001B[33mcallbacks\u001B[39m\u001B[33m\"\u001B[39m: callbacks}\n\u001B[32m    147\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\python\\知识图谱\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:937\u001B[39m, in \u001B[36mBaseChatModel.generate_prompt\u001B[39m\u001B[34m(self, prompts, stop, callbacks, **kwargs)\u001B[39m\n\u001B[32m    928\u001B[39m \u001B[38;5;129m@override\u001B[39m\n\u001B[32m    929\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mgenerate_prompt\u001B[39m(\n\u001B[32m    930\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    934\u001B[39m     **kwargs: Any,\n\u001B[32m    935\u001B[39m ) -> LLMResult:\n\u001B[32m    936\u001B[39m     prompt_messages = [p.to_messages() \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m prompts]\n\u001B[32m--> \u001B[39m\u001B[32m937\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompt_messages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\python\\知识图谱\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:759\u001B[39m, in \u001B[36mBaseChatModel.generate\u001B[39m\u001B[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001B[39m\n\u001B[32m    756\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i, m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(messages):\n\u001B[32m    757\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    758\u001B[39m         results.append(\n\u001B[32m--> \u001B[39m\u001B[32m759\u001B[39m             \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_generate_with_cache\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    760\u001B[39m \u001B[43m                \u001B[49m\u001B[43mm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    761\u001B[39m \u001B[43m                \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    762\u001B[39m \u001B[43m                \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrun_managers\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrun_managers\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    763\u001B[39m \u001B[43m                \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    764\u001B[39m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    765\u001B[39m         )\n\u001B[32m    766\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    767\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m run_managers:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\python\\知识图谱\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1002\u001B[39m, in \u001B[36mBaseChatModel._generate_with_cache\u001B[39m\u001B[34m(self, messages, stop, run_manager, **kwargs)\u001B[39m\n\u001B[32m   1000\u001B[39m     result = generate_from_stream(\u001B[38;5;28miter\u001B[39m(chunks))\n\u001B[32m   1001\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m inspect.signature(\u001B[38;5;28mself\u001B[39m._generate).parameters.get(\u001B[33m\"\u001B[39m\u001B[33mrun_manager\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m-> \u001B[39m\u001B[32m1002\u001B[39m     result = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_generate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1003\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m   1004\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1005\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1006\u001B[39m     result = \u001B[38;5;28mself\u001B[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\python\\知识图谱\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:978\u001B[39m, in \u001B[36mBaseChatOpenAI._generate\u001B[39m\u001B[34m(self, messages, stop, run_manager, **kwargs)\u001B[39m\n\u001B[32m    976\u001B[39m     generation_info = {\u001B[33m\"\u001B[39m\u001B[33mheaders\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28mdict\u001B[39m(raw_response.headers)}\n\u001B[32m    977\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m978\u001B[39m     response = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mclient\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mpayload\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    979\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._create_chat_result(response, generation_info)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\python\\知识图谱\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py:279\u001B[39m, in \u001B[36mrequired_args.<locals>.inner.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    277\u001B[39m             msg = \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mMissing required argument: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mquote(missing[\u001B[32m0\u001B[39m])\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    278\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(msg)\n\u001B[32m--> \u001B[39m\u001B[32m279\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\python\\知识图谱\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:929\u001B[39m, in \u001B[36mCompletions.create\u001B[39m\u001B[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001B[39m\n\u001B[32m    886\u001B[39m \u001B[38;5;129m@required_args\u001B[39m([\u001B[33m\"\u001B[39m\u001B[33mmessages\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mmodel\u001B[39m\u001B[33m\"\u001B[39m], [\u001B[33m\"\u001B[39m\u001B[33mmessages\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mmodel\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mstream\u001B[39m\u001B[33m\"\u001B[39m])\n\u001B[32m    887\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcreate\u001B[39m(\n\u001B[32m    888\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    926\u001B[39m     timeout: \u001B[38;5;28mfloat\u001B[39m | httpx.Timeout | \u001B[38;5;28;01mNone\u001B[39;00m | NotGiven = NOT_GIVEN,\n\u001B[32m    927\u001B[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001B[32m    928\u001B[39m     validate_response_format(response_format)\n\u001B[32m--> \u001B[39m\u001B[32m929\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_post\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    930\u001B[39m \u001B[43m        \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m/chat/completions\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    931\u001B[39m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmaybe_transform\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    932\u001B[39m \u001B[43m            \u001B[49m\u001B[43m{\u001B[49m\n\u001B[32m    933\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmessages\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    934\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmodel\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    935\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43maudio\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43maudio\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    936\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfrequency_penalty\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrequency_penalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    937\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfunction_call\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunction_call\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    938\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfunctions\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunctions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    939\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mlogit_bias\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogit_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    940\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mlogprobs\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogprobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    941\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmax_completion_tokens\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_completion_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    942\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmax_tokens\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    943\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmetadata\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    944\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmodalities\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodalities\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    945\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mn\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    946\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mparallel_tool_calls\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mparallel_tool_calls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    947\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mprediction\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mprediction\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    948\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mpresence_penalty\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mpresence_penalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    949\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mreasoning_effort\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mreasoning_effort\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    950\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mresponse_format\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mresponse_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    951\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mseed\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mseed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    952\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mservice_tier\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mservice_tier\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    953\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstop\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    954\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstore\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstore\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    955\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstream\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    956\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstream_options\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    957\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtemperature\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    958\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtool_choice\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtool_choice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    959\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtools\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtools\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    960\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtop_logprobs\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_logprobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    961\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtop_p\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_p\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    962\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43muser\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43muser\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    963\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mweb_search_options\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mweb_search_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    964\u001B[39m \u001B[43m            \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    965\u001B[39m \u001B[43m            \u001B[49m\u001B[43mcompletion_create_params\u001B[49m\u001B[43m.\u001B[49m\u001B[43mCompletionCreateParamsStreaming\u001B[49m\n\u001B[32m    966\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\n\u001B[32m    967\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mcompletion_create_params\u001B[49m\u001B[43m.\u001B[49m\u001B[43mCompletionCreateParamsNonStreaming\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    968\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    969\u001B[39m \u001B[43m        \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmake_request_options\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    970\u001B[39m \u001B[43m            \u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[43m=\u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_query\u001B[49m\u001B[43m=\u001B[49m\u001B[43mextra_query\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_body\u001B[49m\u001B[43m=\u001B[49m\u001B[43mextra_body\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtimeout\u001B[49m\n\u001B[32m    971\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    972\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m=\u001B[49m\u001B[43mChatCompletion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    973\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    974\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[43m=\u001B[49m\u001B[43mStream\u001B[49m\u001B[43m[\u001B[49m\u001B[43mChatCompletionChunk\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    975\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\python\\知识图谱\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1276\u001B[39m, in \u001B[36mSyncAPIClient.post\u001B[39m\u001B[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[39m\n\u001B[32m   1262\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mpost\u001B[39m(\n\u001B[32m   1263\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   1264\u001B[39m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1271\u001B[39m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] | \u001B[38;5;28;01mNone\u001B[39;00m = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m   1272\u001B[39m ) -> ResponseT | _StreamT:\n\u001B[32m   1273\u001B[39m     opts = FinalRequestOptions.construct(\n\u001B[32m   1274\u001B[39m         method=\u001B[33m\"\u001B[39m\u001B[33mpost\u001B[39m\u001B[33m\"\u001B[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001B[32m   1275\u001B[39m     )\n\u001B[32m-> \u001B[39m\u001B[32m1276\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(ResponseT, \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\python\\知识图谱\\.venv\\Lib\\site-packages\\openai\\_base_client.py:949\u001B[39m, in \u001B[36mSyncAPIClient.request\u001B[39m\u001B[34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[39m\n\u001B[32m    946\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    947\u001B[39m     retries_taken = \u001B[32m0\u001B[39m\n\u001B[32m--> \u001B[39m\u001B[32m949\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    950\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    951\u001B[39m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m=\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    952\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    953\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    954\u001B[39m \u001B[43m    \u001B[49m\u001B[43mretries_taken\u001B[49m\u001B[43m=\u001B[49m\u001B[43mretries_taken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    955\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\python\\知识图谱\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1057\u001B[39m, in \u001B[36mSyncAPIClient._request\u001B[39m\u001B[34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001B[39m\n\u001B[32m   1054\u001B[39m         err.response.read()\n\u001B[32m   1056\u001B[39m     log.debug(\u001B[33m\"\u001B[39m\u001B[33mRe-raising status error\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m-> \u001B[39m\u001B[32m1057\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m._make_status_error_from_response(err.response) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1059\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._process_response(\n\u001B[32m   1060\u001B[39m     cast_to=cast_to,\n\u001B[32m   1061\u001B[39m     options=options,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1065\u001B[39m     retries_taken=retries_taken,\n\u001B[32m   1066\u001B[39m )\n",
      "\u001B[31mBadRequestError\u001B[39m: Error code: 400 - {'error': {'code': 'RequestTimeOut', 'param': None, 'message': 'Request timed out, please try again later.', 'type': 'RequestTimeOut'}, 'id': 'chatcmpl-8d5bbf13-fcb2-95b1-aed4-753888606061', 'request_id': '8d5bbf13-fcb2-95b1-aed4-753888606061'}"
     ]
    }
   ],
   "source": [
    "for txt_file in txt_files:\n",
    "\n",
    "    with open(txt_file, encoding='utf-8', errors='ignore') as f:\n",
    "            text = f.read()\n",
    "\n",
    "    # 创建自定义的 Document 对象\n",
    "    document = Document(\n",
    "        page_content=text,\n",
    "        metadata={\"source\": txt_file}\n",
    "    )\n",
    "\n",
    "    # 处理 Document 对象\n",
    "    documents = [document]\n",
    "    # documents = single_file_loader.load()\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1500,\n",
    "        chunk_overlap=150,\n",
    "        length_function=len,\n",
    "        is_separator_regex=False,\n",
    "    )\n",
    "\n",
    "    pages = splitter.split_documents(documents)\n",
    "    print(f\"Number of chunks for {txt_file.name} = \", len(pages))\n",
    "\n",
    "\n",
    "    df = documents2Dataframe(pages)\n",
    "    print(f\"Shape of DataFrame for {txt_file.name} = \", df.shape)\n",
    "\n",
    "    concepts_list = df2Graph(df, model='gpt-4')\n",
    "    dfg1 = graph2Df(concepts_list)\n",
    "    if not os.path.exists(outputdirectory):\n",
    "        os.makedirs(outputdirectory)\n",
    "    \n",
    "    base_filename = txt_file.stem  \n",
    "    df.to_csv(outputdirectory / f\"{base_filename}_chunks.csv\", sep=\"|\", index=False,encoding=\"utf-8\", quoting=csv.QUOTE_NONE,escapechar='|')\n",
    "    dfg1.to_csv(outputdirectory / f\"{base_filename}_graph.csv\", sep=\"|\", index=False,encoding=\"utf-8\", quoting=csv.QUOTE_NONE,escapechar='|')\n",
    "\n",
    "\n",
    "    dfg1.replace(\"\", np.nan, inplace=True)\n",
    "    dfg1.dropna(subset=[\"node_1\", \"node_2\", 'edge'], inplace=True)\n",
    "    dfg1['count'] = 4 \n",
    "    ## Increasing the weight of the relation to 4. \n",
    "    ## We will assign the weight of 1 when later the contextual proximity will be calculated.  \n",
    "    print(dfg1.shape)\n",
    "\n",
    "    dfg2 = contextual_proximity(dfg1)\n",
    "    dfg2.tail()\n",
    "\n",
    "    dfg = pd.concat([dfg1, dfg2], axis=0)\n",
    "    dfg = (\n",
    "        dfg.groupby([\"node_1\", \"node_2\"])\n",
    "        .agg({\"chunk_id\": \",\".join, \"edge\": ','.join, 'count': 'sum'})\n",
    "        .reset_index()\n",
    "    )\n",
    "    nodes = pd.concat([dfg['node_1'], dfg['node_2']], axis=0).unique()\n",
    "\n",
    "    G = nx.Graph()\n",
    "\n",
    "    ## Add nodes to the graph\n",
    "    for node in nodes:\n",
    "        G.add_node(\n",
    "            str(node)\n",
    "        )\n",
    "\n",
    "    ## Add edges to the graph\n",
    "    for index, row in dfg.iterrows():\n",
    "        G.add_edge(\n",
    "            str(row[\"node_1\"]),\n",
    "            str(row[\"node_2\"]),\n",
    "            title=row[\"edge\"],\n",
    "            weight=row['count']/4\n",
    "        )\n",
    "\n",
    "    communities_generator = nx.community.girvan_newman(G)\n",
    "    top_level_communities = next(communities_generator)\n",
    "    next_level_communities = next(communities_generator)\n",
    "    communities = sorted(map(sorted, next_level_communities))\n",
    "    print(\"Number of Communities = \", len(communities))\n",
    "    print(communities)\n",
    "\n",
    "    palette = \"hls\"\n",
    "\n",
    "    colors = colors2Community(communities)\n",
    "\n",
    "    for index, row in colors.iterrows():\n",
    "        G.nodes[row['node']]['group'] = row['group']\n",
    "        G.nodes[row['node']]['color'] = row['color']\n",
    "        G.nodes[row['node']]['size'] = G.degree[row['node']]\n",
    "\n",
    "    from pyvis.network import Network\n",
    "\n",
    "    graph_output_directory = f\"./docs/{base_filename}_index.html\"\n",
    "\n",
    "    net = Network(\n",
    "        notebook=False,\n",
    "        # bgcolor=\"#1a1a1a\",\n",
    "        cdn_resources=\"remote\",\n",
    "        height=\"900px\",\n",
    "        width=\"100%\",\n",
    "        select_menu=True,\n",
    "        # font_color=\"#cccccc\",\n",
    "        filter_menu=False,\n",
    "    )\n",
    "\n",
    "    net.from_nx(G)\n",
    "    # net.repulsion(node_distance=150, spring_length=400)\n",
    "    net.force_atlas_2based(central_gravity=0.015, gravity=-31)\n",
    "    # net.barnes_hut(gravity=-18100, central_gravity=5.05, spring_length=380)\n",
    "    net.show_buttons(filter_=[\"physics\"])\n",
    "    html_content = net.generate_html()\n",
    "\n",
    "    # Write the HTML content to a file with UTF-8 encoding\n",
    "    with open(graph_output_directory, 'w', encoding='utf-8') as f:\n",
    "        f.write(html_content)\n",
    "    # net.show(graph_output_directory, notebook=False)\n",
    "\n",
    "    # 保存节点信息\n",
    "    nodes_data = []\n",
    "    for node in G.nodes(data=True):\n",
    "        nodes_data.append({\n",
    "            'node': node[0],\n",
    "            'group': node[1].get('group'),\n",
    "            'color': node[1].get('color'),\n",
    "            'size': node[1].get('size')\n",
    "        })\n",
    "\n",
    "    df_nodes = pd.DataFrame(nodes_data)\n",
    "    df_nodes.to_csv(f\"./nodes/{base_filename}_nodes_data.csv\", index=False)\n",
    "\n",
    "    # 保存边信息\n",
    "    edges_data = []\n",
    "    for edge in G.edges(data=True):\n",
    "        edges_data.append({\n",
    "            'node_1': edge[0],\n",
    "            'node_2': edge[1],\n",
    "            'weight': edge[2].get('weight')\n",
    "        })\n",
    "\n",
    "    df_edges = pd.DataFrame(edges_data)\n",
    "    df_edges.to_csv(f\"./nodes/{base_filename}_edges_data.csv\", index=False)\n",
    "    communities_data = []\n",
    "    for group, community in enumerate(communities, 1):\n",
    "        for node in community:\n",
    "            communities_data.append({'node': node, 'group': group})\n",
    "\n",
    "    df_communities = pd.DataFrame(communities_data)\n",
    "    df_communities.to_csv(f\"./nodes/{base_filename}_communities_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
