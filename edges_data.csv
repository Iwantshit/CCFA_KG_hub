node_1,node_2,weight
2d videos,agent,
2d videos,colour,
2d videos,features,
2d videos,frames,
2d videos,graphs,
2d videos,model,
2d videos,position,
2d videos,transformer,
2d videos,type,
2d videos,baby intuitions benchmark,
a. bulling,irene,
a. bulling,m. bortoletto,
abductive commonsense reasoning,learning representations,
ablation studies,irene,
ablation studies,relational graphs,
actions,agent,
actions,context embedding,
actions,context encoder,
actions,ctx token,
actions,embedding vector,
actions,encoded states,
actions,grid-world environment,
actions,irene,
actions,objects,
actions,state encoder,
actions,sub-tasks,
actions,tasks,
actions,trials,
adjacent and aligned,agent's past trajectories,
adjacent and aligned,context encoder,
adjacent and aligned,feature fusion module,
adjacent and aligned,gnn,
adjacent and aligned,local directional relations,
adjacent and aligned,node embeddings,
adjacent and aligned,node features,
adjacent and aligned,prediction net,
adjacent and aligned,remote directional relations,
adjacent and aligned,"type, position, color, shape",
agent,architecture,
agent,baby intuitions benchmark,
agent,bayesian theory of mind,
agent,bib,
agent,bipack,
agent,colour,
agent,common-sense reasoning tasks,
agent,context embedding,
agent,context embeddings,
agent,context encoder,
agent,core psychological reasoning,
agent,ctx token,
agent,edges,
agent,efficient action,
agent,encoded states,
agent,evaluation,
agent,feature fusion module,
agent,features,
agent,frames,
agent,gandhi et al. 2021,
agent,gnn,
agent,graph,
agent,graphs,
agent,grid-world environment,
agent,ground truth,
agent,hbtom,
agent,instrumental action,
agent,irene,
agent,lack of accessible and well-maintained benchmarks,
agent,message passing,
agent,model,
agent,"normalised between [-1, 1]",
agent,"normalised between [0, 1]",
agent,objects,
agent,one-hot vectors,
agent,position,
agent,shape,
agent,spatial relations,
agent,state encoder,
agent,states,
agent,sub-tasks,
agent,tasks,
agent,training and evaluation on the baby intuitions benchmark,
agent,trajectories,
agent,transformer,
agent,transformer context encoder,
agent,trials,
agent,type,
agent,violation of expectation paradigm,
agent,weights,
agent and world state encoding,irene,
agent and world state encoding,rational agents,
agent and world state encoding,training tasks,
agent and world state encoding,graphsage,
agent tests,benchmarks,
agent tests,bib,
agent tests,research,
agent's past trajectories,context encoder,
agent's past trajectories,local directional relations,
agent's past trajectories,node features,
agent's past trajectories,remote directional relations,
agent-blocked instrumental action,evaluation trials,
agent-blocked instrumental action,frame,
agent-blocked instrumental action,graph generation,
agent-blocked instrumental action,instrumental blocking barrier,
agent-blocked instrumental action,json file,
agent-blocked instrumental action,navigation preference,
agent-blocked instrumental action,single-object multiple-agent,
agent-blocked instrumental action,training trials,
agents,existing models,
agents,graph neural network (gnn),
agents,intuitive reasoning network (irene),
agents,irene,
agents,model,
agents,reasoning tasks,
agents,transformer,
agents,video transformer,
agents,vt,
agents’ goals,irene,
agents’ preferences,existing models,
agents’ preferences,graph neural network (gnn),
agents’ preferences,intuitive reasoning network (irene),
agents’ preferences,irene,
agents’ preferences,model,
agents’ preferences,reasoning tasks,
agents’ preferences,video transformer,
agents’ preferences,vt,
ai agents,ai systems,
ai agents,benchmarks,
ai agents,developmental disorders,
ai agents,human-machine collaboration,
ai agents,humans,
ai agents,infants,
ai agents,machine common-sense reasoning,
ai agents,research,
ai agents,robotics,
ai capabilities,baby intuitions benchmark (bib),
ai capabilities,test trials,
ai capabilities,voe paradigm,
ai systems,benchmarks,
ann-sophia,denisov,
ann-sophia,ekta sood,
ann-sophia,hsiu-yu yang,
ann-sophia,manuel mager,
architecture,encoded states,
architecture,grid-world environment,
architecture,objects,
architecture,state encoder,
architecture,sub-tasks,
architecture,tasks,
architecture,trials,
architecture,irene,
attention heads,feature fusion module,
attention heads,gandhi et al.,
attention heads,irene,
attention heads,mlp policy,
attention heads,prediction net,
attention heads,results,
attention heads,state encoder,
attention heads,transformer encoder,
attention is all you need,"advances in neural information processing systems, 30",
baby intuitions benchmark,colour,
baby intuitions benchmark,features,
baby intuitions benchmark,frames,
baby intuitions benchmark,graphs,
baby intuitions benchmark,intuitive reasoning network (irene),
baby intuitions benchmark,irene,
baby intuitions benchmark,model,
baby intuitions benchmark,position,
baby intuitions benchmark,transformer,
baby intuitions benchmark,type,
baby intuitions benchmark (bib),"discerning the goals, preferences, and actions of others",
baby intuitions benchmark (bib),gandhi et al.,
baby intuitions benchmark (bib),initial models,
baby intuitions benchmark (bib),machine theory of mind network,
baby intuitions benchmark (bib),meta-learning problem,
baby intuitions benchmark (bib),models’ ability to predict future actions,
baby intuitions benchmark (bib),"most recent model (hein and diepold 2022, vt)",
baby intuitions benchmark (bib),observer model,
baby intuitions benchmark (bib),test trials,
baby intuitions benchmark (bib),training and evaluation tasks,
baby intuitions benchmark (bib),video,
baby intuitions benchmark (bib),voe paradigm,
bail-largeon 1987,common-sense reasoning,
bail-largeon 1987,expected events or situations,
bail-largeon 1987,gandhi et al.,
bail-largeon 1987,intuitive physics,
bail-largeon 1987,intuitive psychology,
bail-largeon 1987,piloto et al.,
bail-largeon 1987,riochet et al.,
bail-largeon 1987,shu et al.,
bail-largeon 1987,violation of expectation paradigm,
bayesian theory of mind,bib,
bayesian theory of mind,bipack,
bayesian theory of mind,hbtom,
bc-mlp,feature fusion module,
bc-mlp,gandhi et al.,
bc-mlp,irene,
bc-mlp,mlp policy,
bc-mlp,prediction net,
bc-mlp,relational graphs,
bc-mlp,results,
bc-mlp,state encoder,
bc-mlp,transformer encoder,
bc-mlp,video-rnn,
bc-rnn,feature fusion module,
bc-rnn,gandhi et al.,
bc-rnn,irene,
bc-rnn,mlp policy,
bc-rnn,prediction net,
bc-rnn,results,
bc-rnn,state encoder,
bc-rnn,transformer encoder,
behaviour,mindblindness,
benchmarking progress to infant-level physical reasoning in ai,transactions on machine learning research,
benchmarks,bib,
benchmarks,collaborative agents,
benchmarks,evaluating language processing,
benchmarks,general ability of ai systems to reason about unexpected events or situations,
benchmarks,"infants expect other agents to have goals, preferences and engage in instrumental actions",
benchmarks,intelligent,
benchmarks,intuitive physics,
benchmarks,models’ ability to reason about other agents,
benchmarks,research,
benchmarks,visual scene understanding,
"bhagavatula, c.","choi, y.",
bib,bipack,
bib,collaborative agents,
bib,encoded states,
bib,evaluating language processing,
bib,expectedness,
bib,gandhi et al.,
bib,general ability of ai systems to reason about unexpected events or situations,
bib,gnn,
bib,graphsage,
bib,grid-world environment,
bib,hbtom,
bib,hein et al.,
bib,improving performance,
bib,"infants expect other agents to have goals, preferences and engage in instrumental actions",
bib,intelligent,
bib,intuitive physics,
bib,logistic regression classifiers,
bib,lstm,
bib,models’ ability to reason about other agents,
bib,objects,
bib,research,
bib,state encoder,
bib,state-action pairs,
bib,sub-tasks,
bib,tasks,
bib,test trial,
bib,trials,
bib,video frames,
bib,visual scene understanding,
bib,voe paradigm,
bib,vt,
bib task,irene,
bib task,model,
bib task,results,
bipack,hbtom,
blocking barriers,graphsage,
blocking barriers,irene,
blocking barriers,lack of accessible and well-maintained benchmarks,
blocking barriers,lstm,
blocking obstacles,intuitive reasoning network (irene),
blocking obstacles,irene,
clevrer: collision events for video representation and reasoning,international conference on learning representations,
cognitron,self-organizing multi-layered neural network,
collaborative agents,research,
collaborative agents,intelligent,
colour,context embeddings,
colour,edges,
colour,evaluation,
colour,features,
colour,frames,
colour,gandhi et al. 2021,
colour,gnn,
colour,graph,
colour,graphs,
colour,grid-world environment,
colour,ground truth,
colour,message passing,
colour,model,
colour,"normalised between [-1, 1]",
colour,"normalised between [0, 1]",
colour,objects,
colour,one-hot vectors,
colour,position,
colour,shape,
colour,spatial relations,
colour,states,
colour,training and evaluation on the baby intuitions benchmark,
colour,transformer,
colour,type,
colour,violation of expectation paradigm,
colour,weights,
common-sense reasoning,dasgupta et al.,
common-sense reasoning,expected events or situations,
common-sense reasoning,gandhi et al.,
common-sense reasoning,intuitive physics,
common-sense reasoning,intuitive psychology,
common-sense reasoning,intuitive reasoning network (irene),
common-sense reasoning,irene,
common-sense reasoning,piloto et al.,
common-sense reasoning,riochet et al.,
common-sense reasoning,shu et al.,
common-sense reasoning,violation of expectation paradigm,
common-sense reasoning,weihs et al.,
common-sense reasoning,developmental cognitive science,
common-sense reasoning benchmarks,irene,
common-sense reasoning benchmarks,performance,
common-sense reasoning benchmarks,training tasks,
common-sense reasoning tasks,encoded states,
common-sense reasoning tasks,grid-world environment,
common-sense reasoning tasks,objects,
common-sense reasoning tasks,state encoder,
common-sense reasoning tasks,sub-tasks,
common-sense reasoning tasks,tasks,
common-sense reasoning tasks,trials,
commonsense psychology,human infants and machines,
comparing intuitions,"agents’ goals, preferences and actions in human infants",
complementary basic concepts,irene,
complementary basic concepts,lack of accessible and well-maintained benchmarks,
complex tasks,irene,
complex tasks,models,
constantin ruhdorfer,denisov,
constantin ruhdorfer,ekta sood,
constantin ruhdorfer,hsiu-yu yang,
constantin ruhdorfer,manuel mager,
constantin ruhdorfer,m¨uller,
context embedding,context encoder,
context embedding,ctx token,
context embedding,edges,
context embedding,edges eij,
context embedding,embedding vector,
context embedding,encoded states,
context embedding,encoder,
context embedding,gnn,
context embedding,graph-sage layers,
context embedding,grid-world environment,
context embedding,lstm aggregation,
context embedding,message passing,
context embedding,mlp,
context embedding,mlp policy,
context embedding,node embeddings,
context embedding,objects,
context embedding,relationships,
context embedding,rnn,
context embedding,spatial relationships,
context embedding,state embedding,
context embedding,state encoder,
context embedding,sub-tasks,
context embedding,tasks,
context embedding,test frame graph,
context embedding,test state,
context embedding,transformer encoder,
context embedding,trial representations,
context embedding,trials,
context embedding,transformer context encoder,
context embeddings,features,
context embeddings,frames,
context embeddings,graphs,
context embeddings,model,
context embeddings,position,
context embeddings,transformer,
context embeddings,type,
context encoder,ctx token,
context encoder,embedding vector,
context encoder,encoded states,
context encoder,feature fusion module,
context encoder,gnn,
context encoder,grid-world environment,
context encoder,local directional relations,
context encoder,node embeddings,
context encoder,node features,
context encoder,objects,
context encoder,prediction net,
context encoder,remote directional relations,
context encoder,state encoder,
context encoder,sub-tasks,
context encoder,tasks,
context encoder,trials,
context encoder,"type, position, color, shape",
ctx token,embedding vector,
ctx token,encoded states,
ctx token,grid-world environment,
ctx token,objects,
ctx token,state encoder,
ctx token,sub-tasks,
ctx token,tasks,
ctx token,trials,
dasgupta et al.,expected events or situations,
dasgupta et al.,gandhi et al.,
dasgupta et al.,intuitive physics,
dasgupta et al.,intuitive psychology,
dasgupta et al.,piloto et al.,
dasgupta et al.,riochet et al.,
dasgupta et al.,shu et al.,
deep network learning,exponential linear units (elus),
denisov,ekta sood,
denisov,hsiu-yu yang,
denisov,manuel mager,
denisov,m¨uller,
designing and creating new benchmarks,irene,
designing and creating new benchmarks,lack of accessible and well-maintained benchmarks,
designing and creating new benchmarks,general neural common-sense reasoners,
deutsche forschungsgemeinschaft,irene,
deutsche forschungsgemeinschaft,l. shi,
developmental cognitive science,intuitive reasoning network (irene),
developmental cognitive science,irene,
developmental disorders,infants,
edges,embedding vector,
edges,features,
edges,frames,
edges,graphs,
edges,local directional relations,
edges,model,
edges,performance,
edges,position,
edges,relationships,
edges,remote relations,
edges,spatial relations,
edges,state encoder,
edges,transformer,
edges,type,
edges eij,embedding vector,
edges eij,spatial relationships,
efficiency irrational agent,irene,
efficiency irrational agent,relational graphs,
efficient,irene,
efficient,rational agents,
efficient,training tasks,
efficient action,encoded states,
efficient action,grid-world environment,
efficient action,instrumental action,
efficient action,irene,
efficient action,objects,
efficient action,relational graphs,
efficient action,state encoder,
efficient action,sub-tasks,
efficient action,tasks,
efficient action,trials,
efficient action task,irene,
efficient action task,models,
ekta sood,hsiu-yu yang,
ekta sood,manuel mager,
ekta sood,m¨uller,
embedding vector,encoded states,
embedding vector,encoder,
embedding vector,graph-sage layers,
embedding vector,lstm aggregation,
embedding vector,relationships,
embedding vector,spatial relationships,
embedding vector,state encoder,
embedding vector,test state,
embedding vector,transformer encoder,
embedding vector,trial representations,
encoded states,feature fusion module,
encoded states,grid-world environment,
encoded states,instrumental action,
encoded states,irene,
encoded states,objects,
encoded states,state encoder,
encoded states,sub-tasks,
encoded states,tasks,
encoded states,trajectories,
encoded states,transformer context encoder,
encoded states,trials,
errors,feature fusion module,
errors,gandhi et al.,
errors,irene,
errors,mlp policy,
errors,prediction net,
errors,results,
errors,state encoder,
errors,transformer encoder,
evaluating language processing,research,
evaluation,features,
evaluation,frames,
evaluation,graphs,
evaluation,model,
evaluation,position,
evaluation,transformer,
evaluation,type,
evaluation,violation of expectation paradigm,
evaluation performance,graphsage,
evaluation performance,irene,
evaluation performance,lstm,
evaluation performance,training tasks,
evaluation set,preference task,
evaluation set,tasks,
evaluation tasks,feature fusion module,
evaluation tasks,gandhi et al.,
evaluation tasks,irene,
evaluation tasks,mlp policy,
evaluation tasks,prediction net,
evaluation tasks,results,
evaluation tasks,state encoder,
evaluation tasks,transformer encoder,
evaluation tasks,voe accuracy scores,
evaluation trials,graph generation,
evaluation trials,instrumental blocking barrier,
evaluation trials,single-object multiple-agent,
existing models,generalisation,
existing models,graph neural network (gnn),
existing models,infants’ responses,
existing models,intuitive reasoning network (irene),
existing models,irene,
existing models,model,
existing models,neural network,
existing models,rational agents,
existing models,reasoning tasks,
existing models,theory of mind network,
existing models,training tasks,
existing models,transformer,
existing models,video frames,
existing models,video transformer,
existing models,vt,
existing models (gandhi et al. 2021; hein and diepold 2022),irene,
expected events or situations,gandhi et al.,
expected events or situations,intuitive physics,
expected events or situations,intuitive psychology,
expected events or situations,piloto et al.,
expected events or situations,riochet et al.,
expected events or situations,shu et al.,
expected events or situations,violation of expectation paradigm,
expected events or situations,weihs et al.,
expected outcome,observer model,
expected outcome,preference task,
expected outcome,tasks,
expected trials,preference task,
expected trials,tasks,
expectedness,gandhi et al.,
expectedness,hbtom,
expectedness,vt,
familiarisation,preference task,
familiarisation,tasks,
familiarisation,test trials,
fast and accurate deep network learning,exponential linear units,
feature fusion module,gandhi et al.,
feature fusion module,gnn,
feature fusion module,graphsage layers,
feature fusion module,grid-world environment,
feature fusion module,hein et al.,
feature fusion module,hidden dimension 96,
feature fusion module,"hidden dimensions 256, 128 and 256",
feature fusion module,irene,
feature fusion module,local directional relations,
feature fusion module,mean prediction error,
feature fusion module,mlp policy,
feature fusion module,node features,
feature fusion module,objects,
feature fusion module,output dimension two,
feature fusion module,prediction net,
feature fusion module,remote directional relations,
feature fusion module,results,
feature fusion module,stack of six layers,
feature fusion module,state encoder,
feature fusion module,sub-tasks,
feature fusion module,tasks,
feature fusion module,transformer encoder,
feature fusion module,trials,
feature fusion module,video-rnn,
feature fusion module,voe accuracy scores,
feature fusion module,vt model,
features,frames,
features,gandhi et al. 2021,
features,gnn,
features,graph,
features,graphs,
features,grid-world environment,
features,ground truth,
features,message passing,
features,model,
features,"normalised between [-1, 1]",
features,"normalised between [0, 1]",
features,objects,
features,one-hot vectors,
features,position,
features,shape,
features,spatial relations,
features,states,
features,training and evaluation on the baby intuitions benchmark,
features,transformer,
features,type,
features,violation of expectation paradigm,
features,weights,
final scores,local directional relations,
final scores,performance,
final scores,remote relations,
frame,graph generation,
frame,instrumental blocking barrier,
frame,single-object multiple-agent,
frames,gandhi et al. 2021,
frames,gnn,
frames,graph,
frames,graphs,
frames,grid-world environment,
frames,ground truth,
frames,message passing,
frames,model,
frames,"normalised between [-1, 1]",
frames,"normalised between [0, 1]",
frames,objects,
frames,one-hot vectors,
frames,position,
frames,shape,
frames,spatial relations,
frames,states,
frames,training and evaluation on the baby intuitions benchmark,
frames,transformer,
frames,type,
frames,violation of expectation paradigm,
frames,weights,
gandhi et al.,gnn,
gandhi et al.,graphsage layers,
gandhi et al.,hbtom,
gandhi et al.,hein et al.,
gandhi et al.,hidden dimension 96,
gandhi et al.,"hidden dimensions 256, 128 and 256",
gandhi et al.,intuitive physics,
gandhi et al.,intuitive psychology,
gandhi et al.,irene,
gandhi et al.,logistic regression classifiers,
gandhi et al.,mean prediction error,
gandhi et al.,mlp policy,
gandhi et al.,output dimension two,
gandhi et al.,piloto et al.,
gandhi et al.,prediction net,
gandhi et al.,results,
gandhi et al.,riochet et al.,
gandhi et al.,shu et al.,
gandhi et al.,stack of six layers,
gandhi et al.,state encoder,
gandhi et al.,state-action pairs,
gandhi et al.,test trial,
gandhi et al.,test trials,
gandhi et al.,transformer encoder,
gandhi et al.,video frames,
gandhi et al.,video-rnn,
gandhi et al.,violation of expectation paradigm,
gandhi et al.,voe accuracy scores,
gandhi et al.,voe paradigm,
gandhi et al.,vt,
gandhi et al.,vt model,
gandhi et al.,weihs et al.,
gandhi et al. (2021),irene,
gandhi et al. (2021),rational agents,
gandhi et al. (2021),training tasks,
gandhi et al. 2021,graphs,
gandhi et al. 2021,model,
gandhi et al. 2021,position,
gandhi et al. 2021,transformer,
gandhi et al. 2021,type,
gandhi et al. 2021,training and evaluation on the baby intuitions benchmark,
gcn,graphsage,
gcn,irene,
gcn,model,
gcn,results,
general ability of ai systems to reason about unexpected events or situations,research,
general neural common-sense reasoners,irene,
general neural common-sense reasoners,lack of accessible and well-maintained benchmarks,
generalisation,graph neural network (gnn),
generalisation,intuitive reasoning network (irene),
generalisation,irene,
generalisation,model,
generalisation,reasoning tasks,
generalisation,video transformer,
generalisation,vt,
generalisation,training tasks,
gnn,graphs,
gnn,hbtom,
gnn,hein et al.,
gnn,irene,
gnn,local directional relations,
gnn,message passing,
gnn,mlp policy,
gnn,model,
gnn,node embeddings,
gnn,node features,
gnn,performance,
gnn,position,
gnn,prediction net,
gnn,remote directional relations,
gnn,results,
gnn,state embedding,
gnn,state encoder,
gnn,state-action pairs,
gnn,training tasks,
gnn,transformer,
gnn,transformer encoder,
gnn,type,
gnn,vt,
graph,graphs,
graph,model,
graph,position,
graph,transformer,
graph,type,
graph convolutional networks,relational data,
graph generation,instrumental blocking barrier,
graph generation,json file,
graph generation,navigation preference,
graph generation,single-object multiple-agent,
graph generation,training trials,
graph neural network,intuitive reasoning network (irene),
graph neural network,irene,
graph neural network (gnn),infants’ responses,
graph neural network (gnn),intuitive reasoning network (irene),
graph neural network (gnn),irene,
graph neural network (gnn),model,
graph neural network (gnn),neural network,
graph neural network (gnn),rational agents,
graph neural network (gnn),reasoning tasks,
graph neural network (gnn),theory of mind network,
graph neural network (gnn),training tasks,
graph neural network (gnn),transformer,
graph neural network (gnn),video frames,
graph neural network (gnn),video transformer,
graph neural network (gnn),vt,
graph relations,irene,
graph relations,relational graphs,
graph-sage layers,lstm aggregation,
graphs,grid-world environment,
graphs,ground truth,
graphs,local directional relations,
graphs,message passing,
graphs,model,
graphs,"normalised between [-1, 1]",
graphs,"normalised between [0, 1]",
graphs,objects,
graphs,one-hot vectors,
graphs,performance,
graphs,position,
graphs,remote relations,
graphs,shape,
graphs,spatial relations,
graphs,states,
graphs,training and evaluation on the baby intuitions benchmark,
graphs,transformer,
graphs,type,
graphs,violation of expectation paradigm,
graphs,weights,
graphs,irene,
graphsage,improving performance,
graphsage,irene,
graphsage,local directional relations,
graphsage,lstm,
graphsage,model,
graphsage,obstacles,
graphsage,performance,
graphsage,preferences,
graphsage,rational agents,
graphsage,remote relations,
graphsage,results,
graphsage,training tasks,
graphsage,transformer,
graphsage,transformer encoder,
graphsage layers,irene,
graphsage layers,local directional relations,
graphsage layers,mlp policy,
graphsage layers,performance,
graphsage layers,prediction net,
graphsage layers,remote relations,
graphsage layers,results,
graphsage layers,state encoder,
graphsage layers,transformer encoder,
grid-world environment,instrumental action,
grid-world environment,irene,
grid-world environment,model,
grid-world environment,objects,
grid-world environment,position,
grid-world environment,state encoder,
grid-world environment,sub-tasks,
grid-world environment,tasks,
grid-world environment,trajectories,
grid-world environment,transformer,
grid-world environment,transformer context encoder,
grid-world environment,trials,
grid-world environment,type,
ground truth,model,
ground truth,position,
ground truth,transformer,
ground truth,type,
hbtom,hein et al.,
hbtom,logistic regression classifiers,
hbtom,state-action pairs,
hbtom,test trial,
hbtom,video frames,
hbtom,voe paradigm,
hbtom,vt,
hein et al.,irene,
hein et al.,mlp policy,
hein et al.,prediction net,
hein et al.,results,
hein et al.,state encoder,
hein et al.,transformer encoder,
hein et al.,vt,
hein et al.,vt model,
"hein, a.","diepold, k.",
hellaswag: can a machine really finish your sentence?,proceedings of the 57th annual meeting of the association for computational linguistics,
"hendrycks, d.","gimpel, k.",
heuristics,irene,
heuristics,models,
hidden dimension 96,irene,
hidden dimension 96,mlp policy,
hidden dimension 96,prediction net,
hidden dimension 96,results,
hidden dimension 96,state encoder,
hidden dimension 96,transformer encoder,
"hidden dimensions 256, 128 and 256",irene,
"hidden dimensions 256, 128 and 256",mlp policy,
"hidden dimensions 256, 128 and 256",prediction net,
"hidden dimensions 256, 128 and 256",results,
"hidden dimensions 256, 128 and 256",state encoder,
"hidden dimensions 256, 128 and 256",transformer encoder,
hsiu-yu yang,manuel mager,
hsiu-yu yang,m¨uller,
"huang, l.","le bras, r.",
human-robot collaboration,commonsense reasoning,
improving performance,lstm,
inaccessible goal,inaccessible goal task,
inaccessible goal,inconsequential barrier,
inaccessible goal,irene,
inaccessible goal,multi-agent,
inaccessible goal,no barrier,
inaccessible goal,p,
inaccessible goal,preference task,
inaccessible goal,s,
inaccessible goal task,inconsequential barrier,
inaccessible goal task,instrumental action,
inaccessible goal task,instrumental action task,
inaccessible goal task,irene,
inaccessible goal task,m,
inaccessible goal task,multi-agent,
inaccessible goal task,multi-agent task,
inaccessible goal task,no barrier,
inaccessible goal task,p,
inaccessible goal task,preference task,
inaccessible goal task,s,
inconsequential barrier,instrumental action,
inconsequential barrier,instrumental action task,
inconsequential barrier,irene,
inconsequential barrier,m,
inconsequential barrier,multi-agent,
inconsequential barrier,multi-agent task,
inconsequential barrier,no barrier,
inconsequential barrier,p,
inconsequential barrier,preference task,
inconsequential barrier,s,
inductive representation learning,large graphs,
infants,irene,
infants,our model’s expectations,
"infants expect other agents to have goals, preferences and engage in instrumental actions",research,
infants' looking times,irene,
infants' looking times,stojni´c et al. (2023),
infants’ responses,intuitive reasoning network (irene),
infants’ responses,irene,
infants’ responses,model,
infants’ responses,reasoning tasks,
infants’ responses,video transformer,
infants’ responses,vt,
initial models,machine theory of mind network,
initial models,test trials,
initial models,voe paradigm,
input,irene,
input,model,
input,results,
input,remote,
instrumental action,irene,
instrumental action,multi-agent,
instrumental action,no barrier,
instrumental action,objects,
instrumental action,p,
instrumental action,preference task,
instrumental action,relational graphs,
instrumental action,s,
instrumental action,state encoder,
instrumental action,sub-tasks,
instrumental action,tasks,
instrumental action,trials,
instrumental action task,irene,
instrumental action task,multi-agent,
instrumental action task,no barrier,
instrumental action task,p,
instrumental action task,preference task,
instrumental action task,s,
instrumental action tasks,irene,
instrumental action tasks,models,
instrumental blocking barrier,irene,
instrumental blocking barrier,json file,
instrumental blocking barrier,navigation preference,
instrumental blocking barrier,relational graphs,
instrumental blocking barrier,single-object multiple-agent,
instrumental blocking barrier,training trials,
intelligent,research,
intentional stance,12 months of age,
international conference on machine learning,video transformer network,
international conference on machine learning,machine theory of mind,
international conference on machine learning,rectified linear units improve restricted boltzmann machines,
intphys: a framework and benchmark for visual intuitive physics reasoning,ieee transactions on pattern analysis and machine intelligence,
intuitions about support in 4.5-month-old infants,"cognition, 47(2): 121–148",
intuitive physics,coarse probabilistic object representations,
intuitive physics,intuitive psychology,
intuitive physics,piloto et al.,
intuitive physics,research,
intuitive physics,riochet et al.,
intuitive physics,shu et al.,
intuitive physics,violation of expectation paradigm,
intuitive physics,weihs et al.,
intuitive physics learning in a deep-learning model inspired by developmental psychology,nature human behaviour,
intuitive psychology,irene,
intuitive psychology,lack of accessible and well-maintained benchmarks,
intuitive psychology,piloto et al.,
intuitive psychology,riochet et al.,
intuitive psychology,shu et al.,
intuitive psychology,violation of expectation paradigm,
intuitive psychology,weihs et al.,
intuitive reasoning network (irene),irene,
intuitive reasoning network (irene),model,
intuitive reasoning network (irene),neural model,
intuitive reasoning network (irene),neural network,
intuitive reasoning network (irene),rational agents,
intuitive reasoning network (irene),reasoning tasks,
intuitive reasoning network (irene),theory of mind network,
intuitive reasoning network (irene),training tasks,
intuitive reasoning network (irene),transformer,
intuitive reasoning network (irene),video frames,
intuitive reasoning network (irene),video transformer,
intuitive reasoning network (irene),vt,
irene,irrational agent,
irene,irrational agents,
irene,knowledge,
irene,knowledge gained during training,
irene,l. shi,
irene,lack of accessible and well-maintained benchmarks,
irene,local,
irene,local directional relations,
irene,lstm,
irene,lstm limitations,
irene,m,
irene,m. bortoletto,
irene,mean prediction error,
irene,mlp policy,
irene,model,
irene,models,
irene,multi-agent,
irene,multi-agent task,
irene,neural model,
irene,neural network,
irene,no barrier,
irene,novel model,
irene,objects,
irene,our model’s expectations,
irene,output dimension two,
irene,p,
irene,path control,
irene,path control and time control sub-tasks,
irene,performance,
irene,performance scores,
irene,prediction net,
irene,preference,
irene,preference task,
irene,preferences,
irene,rational agents,
irene,reasoning performance,
irene,reasoning tasks,
irene,relational graphs,
irene,remote,
irene,remote relations,
irene,results,
irene,reward hacking,
irene,s,
irene,stack of six layers,
irene,state and context representations,
irene,state encoder,
irene,stojni´c et al. (2023),
irene,sub-tasks,
irene,t-tests,
irene,table 2,
irene,tasks,
irene,the state of the art,
irene,theory of mind network,
irene,time control,
irene,training tasks,
irene,transformer,
irene,transformer encoder,
irene,trials,
irene,unseen evaluation tasks,
irene,video frames,
irene,video transformer,
irene,video-rnn,
irene,voe accuracy scores,
irene,vt,
irene,vt model,
irrational agent,rational agents,
irrational agent,training tasks,
irrational agents,rational agents,
irrational agents,training tasks,
"jiang, m.","rockt¨aschel, t.",
"jiang, z.","minervini, p.",
"jones, l.","gomez, a. n.",
json file,single-object multiple-agent,
"kaiser, ł.","polosukhin, i.",
knowledge,training tasks,
knowledge gained during training,performance,
knowledge gained during training,training tasks,
learning in graph domains,model for learning,
local,model,
local,relational graphs,
local,remote,
local,results,
local directional relations,local relations,
local directional relations,node embeddings,
local directional relations,node features,
local directional relations,nodes,
local directional relations,obstacles,
local directional relations,performance,
local directional relations,prediction net,
local directional relations,remote directional relations,
local directional relations,remote relations,
local directional relations,resulting model,
local directional relations,state encoder,
local directional relations,"type, position, color, shape",
local directional relations,worse scores,
local relations,nodes,
local relations,performance,
local relations,remote relations,
logistic regression classifiers,vt,
lstm,model,
lstm,obstacles,
lstm,performance,
lstm,preferences,
lstm,results,
lstm,training tasks,
lstm,transformer,
lstm,transformer encoder,
lstm limitations,rational agents,
lstm limitations,training tasks,
lstm limitations,transformer,
m,multi-agent,
m,multi-agent task,
m,no barrier,
m,p,
m,preference task,
m,s,
machine common-sense reasoning,research,
machine theory of mind network,test trials,
machine theory of mind network,voe paradigm,
manuel mager,m¨uller,
mean prediction error,mlp policy,
mean prediction error,model,
mean prediction error,prediction net,
mean prediction error,results,
mean prediction error,state encoder,
mean prediction error,transformer encoder,
message passing,model,
message passing,position,
message passing,state embedding,
message passing,transformer,
message passing,type,
meta-learning problem,test trials,
meta-learning problem,voe paradigm,
mlp,rnn,
mlp,state embedding,
mlp policy,output dimension two,
mlp policy,prediction net,
mlp policy,results,
mlp policy,stack of six layers,
mlp policy,state embedding,
mlp policy,state encoder,
mlp policy,transformer encoder,
mlp policy,video-rnn,
mlp policy,voe accuracy scores,
mlp policy,vt model,
model,neural network,
model,"normalised between [-1, 1]",
model,"normalised between [0, 1]",
model,objects,
model,one-hot vectors,
model,position,
model,rational agents,
model,reasoning tasks,
model,relational graphs,
model,remote,
model,results,
model,shape,
model,spatial relations,
model,states,
model,t-tests,
model,table 2,
model,theory of mind network,
model,training and evaluation on the baby intuitions benchmark,
model,training tasks,
model,transformer,
model,type,
model,video frames,
model,video transformer,
model,violation of expectation paradigm,
model,vt,
model,weights,
modeling violation-of-expectation,physical reasoning,
models,path control and time control sub-tasks,
models,reward hacking,
models’ ability to predict future actions,test trials,
models’ ability to predict future actions,voe paradigm,
models’ ability to reason about other agents,research,
"most recent model (hein and diepold 2022, vt)",test trials,
"most recent model (hein and diepold 2022, vt)",video,
"most recent model (hein and diepold 2022, vt)",voe paradigm,
"mota, t.","sridharan, m.",
mse,preference task,
mse,tasks,
mse,prediction error,
multi-agent,multi-agent task,
multi-agent,no barrier,
multi-agent,p,
multi-agent,preference task,
multi-agent,relational graphs,
multi-agent,s,
multi-agent task,no barrier,
multi-agent task,p,
multi-agent task,preference task,
multi-agent task,s,
natural language processing,international joint conference on natural language processing,
navigation preference,single-object multiple-agent,
neural network,reasoning tasks,
neural network,video transformer,
neural network,vt,
no barrier,p,
no barrier,preference task,
no barrier,s,
node embeddings,node features,
node embeddings,remote directional relations,
node embeddings,state embedding,
node features,prediction net,
node features,remote directional relations,
node features,"type, position, color, shape",
nodes,performance,
nodes,remote relations,
"normalised between [-1, 1]",position,
"normalised between [-1, 1]",transformer,
"normalised between [-1, 1]",type,
"normalised between [0, 1]",position,
"normalised between [0, 1]",transformer,
"normalised between [0, 1]",type,
novel model,performance,
novel model,training tasks,
objects,position,
objects,state encoder,
objects,sub-tasks,
objects,tasks,
objects,trajectories,
objects,transformer,
objects,transformer context encoder,
objects,trials,
objects,type,
observer,preference task,
observer,tasks,
observer,voe paradigm,
observer model,preference task,
observer model,tasks,
observer model,test trials,
observer model,voe paradigm,
obstacles,performance,
obstacles,remote relations,
one-hot vectors,position,
one-hot vectors,transformer,
one-hot vectors,type,
output dimension two,prediction net,
output dimension two,results,
output dimension two,state encoder,
output dimension two,transformer encoder,
p,preference task,
p,s,
"parmar, n.","uszkoreit, j.",
path control,relational graphs,
performance,reasoning performance,
performance,remote relations,
performance,resulting model,
performance,state and context representations,
performance,state encoder,
performance,training tasks,
performance,transformer,
performance,unseen evaluation tasks,
performance,worse scores,
performance scores,training tasks,
piloto et al.,riochet et al.,
piloto et al.,shu et al.,
piloto et al.,violation of expectation paradigm,
piloto et al.,weihs et al.,
piqa,physical commonsense in natural language,
position,shape,
position,spatial relations,
position,states,
position,training and evaluation on the baby intuitions benchmark,
position,transformer,
position,type,
position,violation of expectation paradigm,
position,weights,
prediction error,preference task,
prediction error,tasks,
prediction net,remote directional relations,
prediction net,results,
prediction net,stack of six layers,
prediction net,state encoder,
prediction net,transformer encoder,
prediction net,video-rnn,
prediction net,voe accuracy scores,
prediction net,vt model,
preference,relational graphs,
preference task,s,
preference task,tasks,
preference task,test trials,
preference task,training set,
preference task,unexpected trials,
preference task,voe paradigm,
probing physics knowledge using tools from developmental psychology,arxiv preprint arxiv:1804.01128,
rational agents,reasoning tasks,
rational agents,training tasks,
rational agents,transformer,
rational agents,video transformer,
rational agents,vt,
reasoning performance,training tasks,
reasoning tasks,theory of mind network,
reasoning tasks,training tasks,
reasoning tasks,transformer,
reasoning tasks,video frames,
reasoning tasks,video transformer,
reasoning tasks,vt,
relational graphs,remote,
relational graphs,results,
relational graphs,time control,
relational graphs,video-rnn,
relational graphs,vt,
remote,results,
remote directional relations,"type, position, color, shape",
remote relations,resulting model,
remote relations,state encoder,
remote relations,worse scores,
research,visual scene understanding,
resulting model,worse scores,
results,stack of six layers,
results,state encoder,
results,t-tests,
results,table 2,
results,transformer,
results,transformer encoder,
results,video-rnn,
results,voe accuracy scores,
results,vt model,
riochet et al.,shu et al.,
riochet et al.,violation of expectation paradigm,
riochet et al.,weihs et al.,
rnn,state embedding,
shape,transformer,
shape,type,
shu et al.,violation of expectation paradigm,
shu et al.,weihs et al.,
simulation,physical scene understanding,
single-object multiple-agent,training trials,
social iqa: commonsense reasoning about social interactions,proceedings of the 2019 conference on empirical methods in natural language processing and the 9th international joint conference on natural language pro,
solving the baby intuitions benchmark with a hierarchically bayesian theory of mind,robotics: science and systems workshop on social intelligence in humans and robots,
spatial relations,transformer,
spatial relations,type,
stack of six layers,state encoder,
stack of six layers,transformer encoder,
state and context representations,training tasks,
state embedding,state encoder,
state embedding,test frame graph,
state encoder,sub-tasks,
state encoder,tasks,
state encoder,trajectories,
state encoder,transformer context encoder,
state encoder,transformer encoder,
state encoder,trials,
state encoder,video-rnn,
state encoder,voe accuracy scores,
state encoder,vt model,
state encoder,test frame graph,
state-action pairs,vt,
states,transformer,
states,type,
sub-tasks,tasks,
sub-tasks,trajectories,
sub-tasks,transformer context encoder,
sub-tasks,trials,
tasks,tasks,
tasks,test trials,
tasks,training set,
tasks,trajectories,
tasks,transformer context encoder,
tasks,trials,
tasks,unexpected trials,
tasks,voe paradigm,
teachers’ extent of the use of particular task types in mathematics,mathematics education research group of australasia,
test trial,vt,
test trial,voe paradigm,
test trials,training and evaluation tasks,
test trials,video,
test trials,voe paradigm,
theory of mind network,video transformer,
theory of mind network,vt,
training and evaluation on the baby intuitions benchmark,transformer,
training and evaluation on the baby intuitions benchmark,type,
training and evaluation tasks,voe paradigm,
training tasks,transformer,
training tasks,unseen evaluation tasks,
training tasks,video transformer,
training tasks,vt,
trajectories,trials,
transformer,type,
transformer,video transformer,
transformer,violation of expectation paradigm,
transformer,vt,
transformer,weights,
transformer context encoder,trials,
transformer encoder,trial representations,
transformer encoder,video-rnn,
transformer encoder,voe accuracy scores,
transformer encoder,vt model,
type,violation of expectation paradigm,
type,weights,
"vaswani, a.","shazeer, n.",
video,voe paradigm,
video frames,video transformer,
video frames,vt,
video transformer,vt,
video transformer network,ieee/cvf international conference on computer vision,
video transformer network,proceedings of the,
voe paradigm,vt,
winogrande: an adversarial winograd schema challenge at scale,communications of the acm,
